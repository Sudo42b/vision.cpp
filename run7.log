Initializing backend... done (5.7 ms)
- device: CPU - AMD Ryzen 9 5900X 12-Core Processor
Loading model weights from 'models/yolov9t_converted.gguf'... done (161.1 ms)
- float type: f32
- tensor layout: cwhn
- model input size: 640x640
- input image size: 512x512
- tensor layout: CWHN
- processed_f32 shape: 640x640
Image shape: torch.Size([1, 3, 640, 640])
Preprocessing complete (8.9 ms)
Running YOLOv9t inference...
Conv In: ne[0]=3, ne[1]=640, ne[2]=640, ne[3]=1
Weight shape: [3,3,3,16]
Input shape: [3,640,640,1]
Conv: c1=3, c2=16, k=3, s=2, p=1, g=1, d=1, act=True
Conv Out: ne[0]=16, ne[1]=320, ne[2]=320, ne[3]=1
Name: model.4, c1=64, c2=64, c3=64, c4=32, n=3
Name: model.6, c1=96, c2=96, c3=96, c4=48, n=3
Name: model.8, c1=128, c2=128, c3=128, c4=64, n=3
Name: model.12, c1=224, c2=96, c3=96, c4=48, n=3
Name: model.15, c1=160, c2=64, c3=64, c4=32, n=3
Name: model.18, c1=144, c2=96, c3=96, c4=48, n=3
Name: model.21, c1=192, c2=128, c3=128, c4=64, n=3
features size: [22]
x_cat shape: [144,8400,1, 1]
anchor_points shape: [2,8400]
stride_tensor shape: [1,8400]
proj shape: [16,1,1,1]
dfl_output shape: [1,4,8400,1]
distance shape: [1,4,8400,1]
anchor_points shpe: [2,8400,1,1]
dbox shape: [4,8400,1,1]
strides_bc shape: [1,8400,1,1]
cls shape: [80,8400,1,1]
detect_forward complete
outputs.predictions built
Running inference... complete (274.2 ms)
4.6 cat 0.08
3.0 cat 0.08
4.5 cat 0.07
3.0 cat 0.07
27.6 tv 0.00
27.8 tv 0.00
27.8 tv 0.00
3.0 tv 0.00
3.0 bed 0.55
3.0 bed 0.26
3.0 bed 0.22
3.0 bed 0.15
Postprocessing... skipped (no renderer yet)
Detection: bed 55% at [247, 375, 0, 241] (obj_conf: 0.55, cls_conf: 0.55)
Detection: person 47% at [119, 247, 375, 0] (obj_conf: 0.48, cls_conf: 0.48)
Detection: car 46% at [0, 119, 247, 242] (obj_conf: 0.47, cls_conf: 0.47)
Detection: car 42% at [119, 247, 375, 0] (obj_conf: 0.43, cls_conf: 0.43)
Detection: motorcycle 41% at [0, 119, 247, 373] (obj_conf: 0.42, cls_conf: 0.42)
Detection: bicycle 40% at [0, 119, 247, 241] (obj_conf: 0.41, cls_conf: 0.41)
Detection: motorcycle 38% at [372, 0, 119, 246] (obj_conf: 0.38, cls_conf: 0.38)
Detection: hair drier 35% at [165, 332, 499, 512] (obj_conf: 0.36, cls_conf: 0.36)
Detection: potted plant 35% at [375, 0, 119, 0] (obj_conf: 0.35, cls_conf: 0.35)
Detection: person 33% at [247, 375, 0, 237] (obj_conf: 0.33, cls_conf: 0.33)
Detection: bicycle 29% at [119, 247, 375, 0] (obj_conf: 0.29, cls_conf: 0.29)
Detection: airplane 27% at [247, 375, 0, 241] (obj_conf: 0.27, cls_conf: 0.27)
Detection: bed 26% at [0, 119, 247, 241] (obj_conf: 0.26, cls_conf: 0.26)
-> output image saved to ./yolov9t_detections.jpg
Postprocessing complete (86.1 ms)
Found 13 objects
